[["index.html", "Resume 1 Index", " Resume Irene Schimmel 1 Index "],["aside.html", "2 Aside 2.1 Contact info 2.2 Skills 2.3 Traits 2.4 Languages", " 2 Aside 2.1 Contact info Name: Irene Maria Schimmel Date of birth: 22-10-1998 Mobile phone: +31 680138647 LinkedIn: https://www.linkedin.com/in/ireneschimmel/ 2.2 Skills R (programming language) Interdisciplinairy teamwork Problem solving 2.3 Traits Representative Responsible Creative 2.4 Languages Dutch Native English Fluent, C1 "],["main.html", "3 Main 3.1 Irene Schimmel", " 3 Main 3.1 Irene Schimmel library(tidyverse) #version 1.3.0 library(drc) #version 3.0-1 library(readxl) #version 1.3.1 library(ggplot2) #version 3.3.3 knitr::opts_chunk$set(warning=FALSE, message=FALSE) "],["c-elegans-plate-experiment-analysis.html", "4 C. elegans plate experiment analysis", " 4 C. elegans plate experiment analysis There is a lot of data in the file, but not always very logically ordered. There also seem to be quite a lot of missing data points. For RawData and compConcentration, the expected data type is numeric. For compName, the expected data type is character. CE.LIQ.FLOW.062 &lt;- read_excel(here::here(&quot;data/CE.LIQ.FLOW.062_Tidydata.xlsx&quot;)) ##importing file inspect_columns &lt;- CE.LIQ.FLOW.062 %&gt;% dplyr::select(RawData, compName, compConcentration) ##selecting the columns skimr::skim(inspect_columns) ##printing overview of the selected columns (#tab:importing and inspecting file)Data summary Name inspect_columns Number of rows 360 Number of columns 3 _______________________ Column type frequency: character 2 numeric 1 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace compName 0 1 6 26 0 5 0 compConcentration 0 1 1 21 0 16 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist RawData 5 0.99 68.1 26.85 0 51.5 72 88 124  As shown in the overview, RawData and compName have been assigned their expected data types. compConcentration, however, has been assigned a character values. This means that not all data types have been correctly assigned during the importing of the file. CE.LIQ.FLOW.062 %&gt;% ggplot() + geom_point(aes(x = compConcentration, y = RawData, colour = compName, shape = expType))+ theme_minimal() + theme(axis.text.x = element_text(angle=45)) + labs(title = &quot;Scatterplot from C. elegans experiment&quot;, subtitle = &quot;The raw data against the compound concentration&quot;, x = &quot;Compound concentration&quot;, y = &quot;Raw data&quot;) The data type is character. Because of this, the x-axis variables are seen as strings instead of numbers and therefore can not scale them. CE.LIQ.FLOW.062$compConcentration &lt;- gsub(&quot;,&quot;, &quot;.&quot;, CE.LIQ.FLOW.062$compConcentration) ##replace , with . (for data point 259) CE.LIQ.FLOW.062$compConcentration &lt;- as.numeric(CE.LIQ.FLOW.062$compConcentration) ##assign correct data type CE.LIQ.FLOW.062 %&gt;% ggplot() + geom_point(aes(x = log10(compConcentration), y = RawData, colour = compName, shape = expType), position = position_jitter(width = 0.1, height = 0.1), size = 2) + labs(title = &quot;Scatterplot from C. elegans experiment&quot;, subtitle = &quot;The raw data against the compound concentration&quot;, x = &quot;Compound concentration&quot;, y = &quot;Raw data&quot;) + theme_minimal() The positive control for this experiment is Ethanol. The negative control for this experiment is S-medium. To analyze this experiment and learn wheter there is an effect of different concentrations on offspring count and wheter the different compounds have a different IC50 curve: First, the mean of the different concentrations are calculated, per compound. Then, these means are divided by the controlNegative mean to calculate the relative effect per compound per concentration. When these relative values are plotted in a curve, the difference in IC50 (if any) will be shown. Finally, there may be run some statistical tests to indicate whether there is a statistically significant difference between different curves. controlNegative &lt;- CE.LIQ.FLOW.062 %&gt;% filter(expType == &quot;controlNegative&quot;) cn_mean &lt;- mean(controlNegative$RawData) cn_mean / cn_mean ## [1] 1 means &lt;- CE.LIQ.FLOW.062 %&gt;% group_by(compName, compConcentration) %&gt;% summarise(mean = mean(RawData, na.rm = TRUE)) means$relative &lt;- means$mean / cn_mean means %&gt;% ggplot() + geom_point(aes(x = log10(compConcentration), y = relative, colour = compName), position = position_jitter(width = 0.1, height = 0.1), size = 2) + labs(title = &quot;Scatterplot from C. elegans experiment&quot;, subtitle = &quot;The raw data against the compound concentration&quot;, x = &quot;Compound concentration&quot;, y = &quot;Raw data&quot;) + theme_minimal() By viewing the data relatively, it visualizes the differences and similarities between data points more accurately than when viewing them as raw data points. "],["tocilizumab-in-patients-hospitalized-with-covid-19-pneumonia-salama-et-al-2020.html", "5 Tocilizumab in Patients Hospitalized with Covid-19 Pneumonia (Salama et al., 2020)", " 5 Tocilizumab in Patients Hospitalized with Covid-19 Pneumonia (Salama et al., 2020) This study is on the effect of the anti-interleukin-6 receptor antibody tocilizumab in, namely racial and ethnic minority, patients with COVID-19 pneumonia. A total of 389 patients, who were not receiving mechanical ventilation, were randomly assigned either one or two doses of tocilizumab or placebo in a 2:1 ratio. Overall, the tocilizumab reduced the likelihood of progression towards either mechanical ventilation or death, but did not improve survival. Table 1; the transparency criteria. Transparency Criteria Response Study Purpose Yes Data Availability Statement Yes Data Location Supplementary appendix Study Location Yes, Supplementary appendix Author Review Good, author information Ethics Statement Yes Funding Statement Yes Code Availability No "],["mental-health-impacts-in-argentinean-college-students-during-covid-19-quarantine.html", "6 Mental Health Impacts in Argentinean College Students During COVID-19 Quarantine", " 6 Mental Health Impacts in Argentinean College Students During COVID-19 Quarantine Data and original code can be found here The code mainly makes tables from the data and then runs several statistical analyses. The code is very well readable (4/5 score). Line 11 asked for clipboard as input, but this didnt work. I fixed it by using the readxl library and importing dataset with that. All lines where a column name uses . in between words need to be replaced with the column name with spaces. The original code was put in lines: 13, 61, 64, 69, 72, 116, 135, 143, 144, 149 The first 150 lines were fixed. Despite needing to change some of the code, the reproduction of a figure was rather easy (4/5 score). Table 1; the transparency criteria. Transparency Criteria Response Study Purpose Yes Data Availability Statement Yes Data Location Data Availability statement links to the OSF repository Study Location Yes, under Method Author Review Clear Ethics Statement Yes Funding Statement Yes Code Availability Yes # R Code for the manuscript entitled: # &quot;Mental health impacts in Argentinean college students during COVID-19 quarantine&quot;. # López Steinmetz L.C., Leyes C.A., Dutto Florio M.A., Fong S.B., López Steinmetz R.L. &amp; Godoy J.C. ########################################################################## ################## LOAD THE DATASET &amp; PACKAGES ########################### ########################################################################## library(readxl) # Load the dataset # table&lt;-read.table(&quot;clipboard&quot;,header=TRUE, encoding = &quot;Latin 1&quot;, dec=&quot;,&quot;, sep=&quot;\\t&quot;) table &lt;- read_excel(&quot;data/dataset.xlsx&quot;) summary(table) # Load the packages: library(moments) library(gplots) ########################################################################## ###################### METHODS ########################################### ########################################################################## ###### SUB-TITLE: METHOD &gt; Sample and procedure # SAMPLE N = 2687 # Distribution by sex: table(table$SEX) # Absolute frequencies: Women = 2192, Men = 473, Other = 22 prop.table(table(table$SEX))*100 # Percentages: Women = 81.577968%, Men = 17.603275%, Other = 0.818757% # Central tendency measures by age (total sample) # mean mean(table$AGE) # Mean age = 22.74023 # standard deviation sd(table$AGE) # sd age = 3.635612 # median median(table$AGE) # median age = 22 # Distribution by provinces prop.table(table(table$PROVINCE))*100 # JUJ (JUJUY) = 6.6989207% # SAL (SALTA) = 7.1082992% # CBA (CÓRDOBA) = 39.0026051% # STACR (SANTA CRUZ) = 0.9676219% # TDELF (TIERRA DEL FUEGO) = 2.3446223% # CABA (CIUDAD AUTÓNOMA DE BUENOS AIRES) = 11.9464086% # PCIAB (PROVINCIA DE BUENOS AIRES) = 31.9315221% ###### SUB-TITLE: METHOD &gt; Data analysis ### To test Skewness and Kurtosis # Criteria: range of acceptable values or near to (-3 and +3; Brown, 2006). # Reference: Brown T.A. (2006). Confirmatory factor analysis for applied research. New York: Guilford Press. # PSYCH.WELLBEING # skewness(table$PSYCH.WELLBEING) skewness(table$`PSYCH WELLBEING`) # skewness PSYCH.WELLBEING = -0.05214941 # kurtosis(table$PSYCH.WELLBEING) kurtosis(table$`PSYCH WELLBEING`) # kurtosis PSYCH.WELLBEING = 1.951112 # SOC.FUNC.AND.COPING # skewness(table$SOC.FUNC.AND.COPING) skewness(table$`SOC FUNC AND COPING`) # skewness SOC.FUNC.AND.COPING = 0.5326852 # kurtosis(table$SOC.FUNC.AND.COPING) kurtosis(table$`SOC FUNC AND COPING`) # kurtosis SOC.FUNC.AND.COPING = 2.141538 # K10 skewness(table$K10) # skewness K10 = 0.2819622 kurtosis(table$K10) # kurtosis K10 = 2.248409 # BDI skewness(table$BDI) # skewness BDI = 0.6843361 kurtosis(table$BDI) # kurtosis BDI = 2.907102 # STAIR skewness(table$STAIR) # skewness STAIR = 0.02036605 kurtosis(table$STAIR) # kurtosis STAIR = 2.336078 # YAACQ skewness(table$YAACQ) # skewness YAACQ = 1.21683 kurtosis(table$YAACQ) # kurtosis YAACQ = 4.238449 # ISO30 skewness(table$ISO) # skewness ISO30 = 0.4657512 kurtosis(table$ISO) # kurtosis ISO30 = 2.569562 ### For analyses corresponding to the first aim, we divided the entire sample into four groups: table(table$REGIONS) # NORTH = 371 # CENTER = 1048 # SOUTH = 89 # MOST POPULATED = 1179 ### For analyses corresponding to the second aim, we divided the entire sample into four groups: #table(table$SUB.PERIODS.IN.PRE.AND.POST) table(table$`SUB PERIODS IN PRE AND POST`) # first week pre-quarantine extension (ONE WEEK PRE) = 1508 # second week pre-quarantine extension (TWO WEEK PRE) = 525 # first week post-quarantine extension (ONE WEEK POST) = 364 # remaining weeks post-quarantine extension (REMAINING WEEKS POST) = 290 ########################################################################## ###################### RESULTS ########################################### ########################################################################## ########################################################################## ####################### AIM 1 ############################################ ########################################################################## ### Differences in mental health aspects (both general and specific) by four regions # PSYCHOLOGICAL WELL-BEING/DISCOMFORT (OF GENERAL HEALTH) # anovaregpsychwellbeing &lt;- aov(table$PSYCH.WELLBEING~table$REGIONS) anovaregpsychwellbeing &lt;- aov(table$`PSYCH WELLBEING`~table$REGIONS) summary(anovaregpsychwellbeing) plot(anovaregpsychwellbeing) "],["working-with-databases.html", "7 Working with databases", " 7 Working with databases This exercise shows my work with SQL and PostgreSQL in DBeaver, and the relation from and to R in Rstudio. Starting with some setup and loading and tidying of data in Rstudio. library(tidyverse) #version 1.3.1 library(dslabs) #version 0.7.4 library(RPostgres) #version 1.3.2 df_flu &lt;- read.csv(&quot;data/flu_data.csv&quot;, skip = 11) df_dengue &lt;- read.csv(&quot;data/dengue_data.csv&quot;, skip = 11) df_gapminder &lt;- gapminder df_flu &lt;- df_flu %&gt;% gather(key = &quot;country&quot;, value = &quot;activity&quot;, -Date) df_dengue &lt;- df_dengue %&gt;% gather(key = &quot;country&quot;, value = &quot;activity&quot;, -Date) Making sure the datasets coincide on variables, so they may be used together. df_flu &lt;- separate(df_flu, Date, into = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), sep = &#39;-&#39;) df_flu$year &lt;- as.integer(df_flu$year) df_flu$country &lt;- as.factor(df_flu$country) df_dengue &lt;- separate(df_dengue, Date, into = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), sep = &#39;-&#39;) df_dengue$year &lt;- as.integer(df_dengue$year) df_dengue$country &lt;- as.factor(df_dengue$country) And storing them for safe-keeping! write_csv(df_flu, here::here(&quot;data\\\\df_flu.csv&quot;)) write_rds(df_flu, here::here(&quot;data\\\\df_flu.rds&quot;)) write_csv(df_dengue, here::here(&quot;data\\\\df_dengue.csv&quot;)) write_rds(df_dengue, here::here(&quot;data\\\\df_dengue.rds&quot;)) write_csv(df_gapminder, here::here(&quot;data\\\\gapminder.csv&quot;)) write_rds(df_gapminder, here::here(&quot;data\\\\df_gapminder.rds&quot;)) Then inserting them into a premade PostgreSQL database in DBeaver. # con &lt;- dbConnect(RPostgres::Postgres(), # dbname = &quot;workflowsdb&quot;, # host = &quot;localhost&quot;, # port = &quot;5432&quot;, # user = &quot;postgres&quot;, # password = &quot;password&quot;) # dbWriteTable(con, &quot;df_flu&quot;, df_flu) # dbWriteTable(con, &quot;df_dengue&quot;, df_dengue) # dbWriteTable(con, &quot;df_gapminder&quot;, df_gapminder) # dbDisconnect(con) And inspecting the data to see if the transfer went properly. # in dbeaver knitr::include_graphics( here::here( &quot;images&quot;, &quot;dbeaver_screenshot.png&quot; ) ) # in Rstudio head(df_flu) ## year month day country activity ## 1 2002 12 29 Argentina NA ## 2 2003 01 05 Argentina NA ## 3 2003 01 12 Argentina NA ## 4 2003 01 19 Argentina NA ## 5 2003 01 26 Argentina NA ## 6 2003 02 02 Argentina 136 head(df_dengue) ## year month day country activity ## 1 2002 12 29 Argentina NA ## 2 2003 01 05 Argentina NA ## 3 2003 01 12 Argentina NA ## 4 2003 01 19 Argentina NA ## 5 2003 01 26 Argentina NA ## 6 2003 02 02 Argentina NA head(df_gapminder) ## country year infant_mortality ## 1 Albania 1960 115.40 ## 2 Algeria 1960 148.20 ## 3 Angola 1960 208.00 ## 4 Antigua and Barbuda 1960 NA ## 5 Argentina 1960 59.87 ## 6 Armenia 1960 NA ## life_expectancy fertility population gdp ## 1 62.87 6.19 1636054 NA ## 2 47.50 7.65 11124892 13828152297 ## 3 35.98 7.32 5270844 NA ## 4 62.97 4.43 54681 NA ## 5 65.39 3.11 20619075 108322326649 ## 6 66.86 4.55 1867396 NA ## continent region ## 1 Europe Southern Europe ## 2 Africa Northern Africa ## 3 Africa Middle Africa ## 4 Americas Caribbean ## 5 Americas South America ## 6 Asia Western Asia The gapminder dataset needed some cleaning and ofcourse this new, clean dataset needed to be put in the database as well. clean_gapminder &lt;- df_gapminder %&gt;% na.omit() # con &lt;- dbConnect(RPostgres::Postgres(), # dbname = &quot;workflowsdb&quot;, # host = &quot;localhost&quot;, # port = &quot;5432&quot;, # user = &quot;postgres&quot;, # password = &quot;password&quot;) # dbWriteTable(con, &quot;clean_gapminder&quot;, clean_gapminder) # dbDisconnect(con) knitr::include_graphics( here::here( &quot;images&quot;, &quot;db_screenshot2.png&quot; ) ) Then joining them using SQL and putting the joined dataset back in Rstudio to show some desciptive statistics and graphs. knitr::include_graphics(here::here( &quot;images&quot;, &quot;db_screenshot3.png&quot; )) joined_dfs &lt;- read.csv(&quot;data/joined_dfs_202106171226.csv&quot;) summary(joined_dfs) ## infant_mortality flu_activity dengue_activity ## Min. :12.70 Min. : 56.0 Min. :0.0040 ## 1st Qu.:14.80 1st Qu.: 178.0 1st Qu.:0.0270 ## Median :16.60 Median : 268.0 Median :0.0560 ## Mean :22.65 Mean : 441.6 Mean :0.0982 ## 3rd Qu.:27.05 3rd Qu.: 539.0 3rd Qu.:0.1080 ## Max. :53.70 Max. :3041.0 Max. :1.0000 ## NA&#39;s :2551 NA&#39;s :366 ## year country ## Min. :2002 Length:97768 ## 1st Qu.:2005 Class :character ## Median :2007 Mode :character ## Mean :2007 ## 3rd Qu.:2009 ## Max. :2011 ## tidy_dfs &lt;- joined_dfs %&gt;% gather(&#39;infant_mortality&#39;, &#39;flu_activity&#39;, &#39;dengue_activity&#39;, key = &quot;group&quot;, value = &quot;activity&quot;, na.rm = TRUE) tidy_dfs %&gt;% filter(activity &lt;= 540) %&gt;% ggplot(aes(x = group, y = activity)) + geom_boxplot(aes(fill = group)) + labs(title = &quot;Boxplot of the activity per group&quot;, x = &quot;&quot;, y = &quot;Activity&quot;, caption = &quot;Data from the flu_data, dengue_data and gapminder datasets&quot;) + theme_minimal() tidy_dfs %&gt;% ggplot(aes(x = country, y = activity)) + geom_boxplot(aes(fill = country)) + labs(title = &quot;Boxplot of the activity per country&quot;, x = &quot;&quot;, y = &quot;Activity&quot;, caption = &quot;Data from the flu_data, dengue_data and gapminder datasets&quot;) + theme_minimal() tidy_dfs %&gt;% filter(group == &quot;flu_activity&quot;) %&gt;% ggplot(aes(x = year, y = activity)) + geom_smooth() + labs(title = &quot;Graph of the average flu activity per year&quot;, x = &quot;Year&quot;, y = &quot;Activity&quot;, caption = &quot;Data from the flu_data dataset&quot;) + theme_minimal() "],["portfolio-assignment-6-2.html", "8 Portfolio assignment 6.2", " 8 Portfolio assignment 6.2 In a little more than two years from now, Id like to be graduating the Applied Data Science master at University Utrecht. This minor is a great prerequisite, as it focuses on R and statistics. Besides that, however, the master also requires basic knowledge of data-analysis and statistics in Python. While the data-analysis and statistics knowledge overall will be the same, Ill need to know how to do these things using Python. Therefore, I will spend this courses free time studying Python, with a focus on data-analysis and statistics. I will start by doing some tutorials on the BeginnersGuide. Then, I will do at least this tutorial on data-analysis using Python. Maybe more, depending on the time it takes. After that, I will walk through this tutorial to get some insight in how to use statistics in Python. This tutorial also incorporates some data wrangling, so it will be a nice addition. While I realize that this obviously isnt enough to learn Python, I think itll make for a great start. Ill try and learn some more over the summer, probably asking some tutoring from my friends that already have a lot of experience using Python (they better be glad, seeing as how theyre always bugging me to start learning it). "]]
